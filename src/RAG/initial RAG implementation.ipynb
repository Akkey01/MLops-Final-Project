{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31f6e35-b43a-45f7-85c2-5e13b77b092a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90c1084-2ac3-4226-8f34-335cbfeba950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c6aa64-3a17-4fd5-a9ea-e58ff9ee809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary_from_xml(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Extract all text from the XML (adjust tag logic if needed)\n",
    "    text_chunks = []\n",
    "    for elem in root.iter():\n",
    "        if elem.text and elem.text.strip():\n",
    "            text_chunks.append(elem.text.strip())\n",
    "    \n",
    "    return \" \".join(text_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0037c0-c692-4839-8bea-2e7ddce1a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_summaries(folder_path):\n",
    "    summaries = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".abssumm.xml\"):\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            summary_text = extract_summary_from_xml(full_path)\n",
    "            if summary_text:\n",
    "                summaries.append({\n",
    "                    \"filename\": filename,\n",
    "                    \"text\": summary_text\n",
    "                })\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c5eb1bd-37ef-4feb-a86f-786912ffc5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 142 summaries\n",
      "ES2002a.abssumm.xml\n",
      "The project manager introduced the upcoming project to the team members and then the team members participated in an exercise in which they drew their favorite animal and discussed what they liked about the animal. The project manager talked about the project finances and selling prices. The team then discussed various features to consider in making the remote. The industrial designer will work on the working design of the remote. The user interface designer will work on the technical functions \n"
     ]
    }
   ],
   "source": [
    "# Update with the path to your `abstractive` folder\n",
    "ami_folder = r\"ami_public_manual_1.6.2\\abstractive\"\n",
    "summaries = load_all_summaries(ami_folder)\n",
    "\n",
    "# Quick check\n",
    "print(f\"Loaded {len(summaries)} summaries\")\n",
    "print(summaries[0]['filename'])\n",
    "print(summaries[0]['text'][:500])  # Preview first 500 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "109e3087-d0cb-4c64-952c-dbff43c704f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39202107-07ee-42b8-ba73-d273f222d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "# Load GPT-2 tokenizer (used by OpenAI for estimating token counts)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ef9d1c2-59a6-45c2-9af2-f2c5844f0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_tokens=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for word in words:\n",
    "        token_len = len(tokenizer.encode(word, add_special_tokens=False))\n",
    "        if current_tokens + token_len > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_tokens = token_len\n",
    "        else:\n",
    "            current_chunk.append(word)\n",
    "            current_tokens += token_len\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b40df4f6-4619-43e2-9f2e-2b3ad3597d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 160\n",
      "{'filename': 'ES2002a.abssumm.xml', 'chunk_id': 0, 'text': 'The project manager introduced the upcoming project to the team members and then the team members participated in an exercise in which they drew their favorite animal and discussed what they liked about the animal. The project manager talked about the project finances and selling prices. The team then discussed various features to consider in making the remote. The industrial designer will work on the working design of the remote. The user interface designer will work on the technical functions of the remote. The marketing executive will work on what requirements the remote has to fulfill The remote will sell for 25 Euro. The remote will be sold on an international scale. The production costs cannot exceed 12.50 Euro. Whether the remote will be used exclusively for televisions.'}\n"
     ]
    }
   ],
   "source": [
    "chunked_data = []\n",
    "\n",
    "for summary in summaries:\n",
    "    chunks = chunk_text(summary[\"text\"], max_tokens=500)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunked_data.append({\n",
    "            \"filename\": summary[\"filename\"],\n",
    "            \"chunk_id\": i,\n",
    "            \"text\": chunk\n",
    "        })\n",
    "\n",
    "print(f\"Total chunks created: {len(chunked_data)}\")\n",
    "print(chunked_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd03eab7-0477-4001-b5bc-25642173a409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\aksha\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.51.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de861266-52a6-4a1a-b372-c9a8e8b995f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Fast, small, good quality\n",
    "\n",
    "def get_local_embedding(text):\n",
    "    return embedding_model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fffa2b4f-7d60-4259-b6ec-a3a9ff387bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [item['text'] for item in chunked_data]\n",
    "embeddings = [get_local_embedding(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee8ab7bd-3c5b-408d-9462-0b4f9a124585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index contains 160 vectors\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "dimension = len(embeddings[0])  # should be 384 for MiniLM\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings).astype('float32'))\n",
    "\n",
    "print(f\"FAISS index contains {index.ntotal} vectors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe4c4aa-96ed-43c3-a048-d6a284c73b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f185c54-138f-48fa-9d35-0b6faf4dfd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "TOGETHER_API_KEY = \"cc4b628095c0531f06fe08ff20e1f0bad8cf4e6c39ed2b3c70744a6278a7faab\"  # paste the key from your dashboard\n",
    "\n",
    "def generate_answer(prompt, model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"):\n",
    "    url = \"https://api.together.xyz/v1/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    result = response.json()\n",
    "\n",
    "    try:\n",
    "        return result[\"choices\"][0][\"text\"]\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error parsing Together.ai response:\")\n",
    "        print(result)\n",
    "        return \"No output returned.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af53a848-87f7-4059-b138-a3c6a0712f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_faiss(query, top_k=5):\n",
    "    query_embedding = get_local_embedding(query)\n",
    "    D, I = index.search(np.array([query_embedding]).astype('float32'), top_k)\n",
    "    return [chunked_data[i]['text'] for i in I[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5af8ae5e-40cd-454e-b4b0-df913022c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_rag_agent(query):\n",
    "    top_chunks = search_faiss(query, top_k=5)\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    prompt = f\"\"\"You are a helpful meeting assistant.\n",
    "Based on the following context from AMI meeting summaries, answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    return generate_answer(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ad992ab-d2f6-4499-b584-c74677db0f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " In meeting TS3008a, the following key decisions were made:\n",
      "\n",
      "1. The remote will not include teletext and will be only for TV use.\n",
      "2. The target group is users under 40.\n",
      "3. The remote will feature the corporate logo and color.\n",
      "4. The remote will have an LCD screen and speech recognition.\n",
      "5. The advanced functions such as audio settings, contrast and channel programming will be accessed through the screen.\n",
      "6. The remote will have buttons for basic functions and make the advanced functions accessible through the screen.\n",
      "7. The remote will have buttons for power, volume selection, channel selection, digits from zero to nine, mute, a menu for teletext, a battery indicator, to access double digits, screen settings, channel settings, and audio settings.\n",
      "8. The remote will have a rechargeable battery which comes with a charger.\n",
      "9. The remote will allow users to have the possibility to enlarge the buttons.\n",
      "10. The remote will have a general menu with the most used functions.\n",
      "11. The remote will be button-less.\n",
      "12. The remote will shut down when the television shuts down.\n",
      "13. The remote will go into standby when idle.\n",
      "14. The LCD screen will have a low battery indicator.\n"
     ]
    }
   ],
   "source": [
    "response = ask_rag_agent(\"What were the key decisions made in meeting TS3008a?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f59b2040-3a0a-4bc4-b8d0-7afde3da5bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The main speaker in ES2002b was the User Interface Designer, who presented the major components of the interface design, dividing the interface into two parts: voice commands and buttons. The Marketing Expert was also a key speaker, as she reported on research which shows that users think most remotes are ugly, easily lost and bad for RSI. Audio settings are rarely used, and the power, channel and volume buttons are used most often. The remote should be user-friendly and have a good look and feel.\n",
      "\n",
      "The usability concerns in TS3010b were that remotes were too difficult to use, users want fancier and more ergonomic designs, shock protection, voice recognition, and LCD screens. The Project Manager also announced a new requirement that the remote is only to control televisions. The group decided to eliminate the LCD screen and voice recognition from the design due to time and cost restraints. They also decided to include a previous channel change button to the standard remote buttons, and to have a wheel for changing channels in increments, with a smaller number pad below it. The remote will not have an LCD screen. The remote will not include speech recognition. The group experienced many technical difficulties with their presentations; all participants encountered problems when opening their presentations.\n"
     ]
    }
   ],
   "source": [
    "response = ask_rag_agent(\"Who was the main speaker in ES2002b and What were the usability concerns in TS3010b\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad0bbb9c-62fc-4cc0-9b8e-4a57d95d2c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Action Items from the Meeting:\n",
      "\n",
      "1. Gather more information for the next meeting, the functional design meeting. (All Participants)\n",
      "2. Decide on the inclusion of speech recognition in the design. (All Participants)\n",
      "3. Determine the target group and features to attract them. (All Participants)\n",
      "4. Discuss and decide on the buttons for the remote control. (All Participants)\n",
      "5. Create the design of the remote control. (To be decided in the next meeting)\n",
      "6. Industrial Designer: Work on the working design and technical function.\n",
      "7. User Interface Designer: Work on the working design and functional design.\n",
      "8. Marketing Manager: Look for user requirement specifications such as friendliness, selling price, and profit.\n",
      "9. Consider the possibility of a touch screen, LCD, and other functions. (All Participants)\n",
      "10. Fill out the questionnaire. (All Participants)\n",
      "11. Receive specific instructions for the next meeting by email. (All Participants)\n"
     ]
    }
   ],
   "source": [
    "response = ask_rag_agent(\"TS3010b give the action items of this meeting, and who is responsible for what and write the name of person wherever possible?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e615257d-9e8c-4d51-a9f6-ad0adb26312f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
